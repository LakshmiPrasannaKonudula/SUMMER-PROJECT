import numpy as np 
import pandas as pd 
import re  
import csv
import nltk 
from random import choices
from string import *
nltk.download('stopwords')  
from nltk.corpus import stopwords 
twetext = pd.read_csv('/Users/SaiUday/Downloads/elonmusk_tweets.csv')
all_sentences=list(twetext['text'])
#print(all_sentences)
merge_sentence=' '.join(all_sentences)
user_name = re.findall("@\w+",merge_sentence)
#print(user_name)
uniq_usernames = list( dict.fromkeys(user_name) )
random_values = ["@"+"".join(choices(ascii_lowercase, k=10)) for _ in range(len(uniq_usernames))]
#print(random_values)
masking_dict=dict(zip(uniq_usernames, random_values))
#print(masking_dict)
twetext['text_new'] = twetext['text'].replace(masking_dict, regex=True)
#print(twetext['text_new'])
from sklearn.feature_extraction.text import CountVectorizer
count = CountVectorizer()
bag_of_words = count.fit_transform(twetext['text_new'])
#print(bag_of_words)
#test=count.fit(twetext['text_new'])
#print(test)
# Get feature names
feature_names = count.get_feature_names()

# View feature names
#print(feature_names)

#count_list = feature_names.toarray().sum(axis=0)  
#print(count_list)
bagofwordstofile=bag_of_words.toarray()
count_of_words=bag_of_words.toarray().sum(axis=0)

count_dict=dict(zip(feature_names,count_of_words))
#print(count_dict)
#print(bagofwordstofile)

np.savetxt("/Users/SaiUday/Downloads/bagofwordstofile.csv", bagofwordstofile, delimiter=",")
#np.savetxt("/Users/SaiUday/Downloads/count_dictionary.csv", count_dict, delimiter=",")

#mydata=twetext['text_new'].str.lower().tolist()
#print(mydata)

from sklearn.feature_extraction.text import TfidfVectorizer
sklearn_tfidf = TfidfVectorizer(norm='l2',min_df=0, use_idf=True, smooth_idf=False, sublinear_tf=True, tokenizer=tokenize)
sklearn_representation = sklearn_tfidf.fit_transform(all_documents)

rows=twetext.shape[0]
print(rows)
# transforminhg into feature matrix
with open('/Users/SaiUday/Downloads/variable.csv', 'wb') as abc:
    for i in range(rows):
        variable=np.round(sklearn_representation[i].toarray(),4)
    #print(sklearn_tfidf.vocabulary_)
        print(variable)
        #np.savetxt("/Users/SaiUday/Downloads/variable.csv",variable, delimiter=",")
        np.savetxt(abc, variable,fmt='%1.9f', delimiter=",")
    
